{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mountain beach: run from saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case: Not found: No algorithm worked!\n",
    "# In case: This is probably because cuDNN failed to initialize\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved = \"../saved_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: using pretrained inceptionv3 -> more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pre_inceptionv3_100e_94\n",
    "# path_model = path_saved + \"model_100e_945_pre_imagenet_inceptionv3_200_moredata.h5\"\n",
    "path_model = path_saved + \"SavedModel_100e_945_pre_imagenet_inceptionv3_200_moredata\"\n",
    "model = tf.keras.models.load_model(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dim = (200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "base_dir = \"../dataset/beach_mountain_more\"\n",
    "\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "test_beach_dir = os.path.join(test_dir, 'beach')\n",
    "test_moutain_dir = os.path.join(test_dir, 'mountain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 929 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "test_generator =  test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    batch_size  = batch_size,\n",
    "    class_mode  = 'binary', \n",
    "    target_size = im_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 7s 164ms/step - loss: 0.1661 - accuracy: 0.9429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16611820459365845, 0.9429494142532349]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "steps = test_generator.n // test_generator.batch_size\n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'beach', 1: 'mountain'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the labels\n",
    "labels = (test_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beach',\n",
       " 'mountain',\n",
       " 'beach',\n",
       " 'beach',\n",
       " 'beach',\n",
       " 'beach',\n",
       " 'mountain',\n",
       " 'beach',\n",
       " 'beach',\n",
       " 'mountain']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_generator)\n",
    "predicted_class_indices= (pred>0.5).astype(\"int32\")\n",
    "predictions = [labels[k[0]] for k in predicted_class_indices]\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.4934592e-05]]\n",
      "beach11.jpeg is a beach\n",
      "\n",
      "[[0.99999845]]\n",
      "mountain6.jpg is a mountain\n",
      "\n",
      "[[0.9927979]]\n",
      "mountain9.jpg is a mountain\n",
      "\n",
      "[[8.310272e-08]]\n",
      "beach9.jpg is a beach\n",
      "\n",
      "[[0.00864518]]\n",
      "beach12.jpeg is a beach\n",
      "\n",
      "[[0.98329276]]\n",
      "beach8.jpeg is a mountain\n",
      "\n",
      "[[0.9992749]]\n",
      "mountain2.jpg is a mountain\n",
      "\n",
      "[[0.99995327]]\n",
      "mountain5.jpg is a mountain\n",
      "\n",
      "[[0.99391985]]\n",
      "mountain1.jpg is a mountain\n",
      "\n",
      "[[0.99772483]]\n",
      "mountain5.jpeg is a mountain\n",
      "\n",
      "[[0.5486794]]\n",
      "beach1.jpg is a mountain\n",
      "\n",
      "[[0.63761824]]\n",
      "mountain3.jpg is a mountain\n",
      "\n",
      "[[0.0002816]]\n",
      "beach5.jpeg is a beach\n",
      "\n",
      "[[0.05558277]]\n",
      "beach3.jpg is a beach\n",
      "\n",
      "[[0.17985249]]\n",
      "mountain4.png is a beach\n",
      "\n",
      "[[0.15208359]]\n",
      "beach6.jpg is a beach\n",
      "\n",
      "[[0.0001361]]\n",
      "beach10.jpeg is a beach\n",
      "\n",
      "[[4.6182063e-06]]\n",
      "beach4.jpeg is a beach\n",
      "\n",
      "[[0.36505738]]\n",
      "beach2.jpeg is a beach\n",
      "\n",
      "[[0.37608698]]\n",
      "beach7.jpeg is a beach\n",
      "\n",
      "[[0.69592005]]\n",
      "mountain8.jpeg is a mountain\n",
      "\n",
      "[[0.9999999]]\n",
      "mountain7.jpg is a mountain\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict for an uploaded image\n",
    "file_path = '../dataset/beach_mountain/internet/' # current dir\n",
    "# file_path = '../dataset/beach_mountain/test/beach/' # current dir\n",
    "# file_path = '../dataset/beach_mountain/test/mountain/' # current dir\n",
    "test_files = os.listdir(file_path)\n",
    "\n",
    "for file in test_files:\n",
    "    # predicting images\n",
    "    path=file_path + file\n",
    "    img=image.load_img(path, target_size=im_dim)\n",
    "    x=image.img_to_array(img)\n",
    "    x=x/255\n",
    "    x=np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "    \n",
    "    classes = model.predict(images)\n",
    "    print(classes)\n",
    "    classes = (classes > 0.5).astype(\"int32\")[0][0]\n",
    "#     print(classes)\n",
    "\n",
    "    if classes>0:\n",
    "        print(file + \" is a mountain\\n\")\n",
    "    else:\n",
    "        print(file + \" is a beach\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 200, 200, 3)\n",
      "(1, 200, 200, 3)\n",
      "mountain1.jpg is a mountain\n"
     ]
    }
   ],
   "source": [
    "# from an image\n",
    "test_file = \"../dataset/beach_mountain/internet/mountain1.jpg\"\n",
    "img = image.load_img(test_file, target_size=im_dim)\n",
    "x = image.img_to_array(img)\n",
    "x = x/255\n",
    "x = np.expand_dims(x, axis=0)\n",
    "print(x.shape)\n",
    "images = np.vstack([x])\n",
    "print(images.shape)\n",
    "\n",
    "classes = model.predict(images)\n",
    "classes = (classes > 0.5).astype(\"int32\")[0]\n",
    "\n",
    "if classes>0:\n",
    "    print(test_file.split(\"/\")[-1] + \" is a mountain\")\n",
    "else:\n",
    "    print(test_file.split(\"/\")[-1] + \" is a beach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: using pretrained inceptionv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pre_inceptionv3_100e_94\n",
    "path_model = path_saved + \"model_pre_inceptionv3_100e_94.h5\"\n",
    "model_1 = tf.keras.models.load_model(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "base_dir = \"../dataset/beach_mountain\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "train_beach_dir = os.path.join(train_dir, 'beach')\n",
    "train_moutain_dir = os.path.join(train_dir, 'mountain')\n",
    "\n",
    "validation_beach_dir = os.path.join(validation_dir, 'beach')\n",
    "validation_mountain_dir = os.path.join(validation_dir, 'mountain')\n",
    "\n",
    "test_beach_dir = os.path.join(test_dir, 'beach')\n",
    "test_moutain_dir = os.path.join(test_dir, 'mountain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "test_generator =  test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    batch_size  = batch_size,\n",
    "    class_mode  = 'binary', \n",
    "    target_size = img_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 4s 62ms/step - loss: 0.1182 - accuracy: 0.9550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11820552498102188, 0.9549999833106995]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "steps = test_generator.n // test_generator.batch_size\n",
    "model_1.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'beach', 1: 'mountain'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the labels\n",
    "labels = (test_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beach',\n",
       " 'mountain',\n",
       " 'mountain',\n",
       " 'mountain',\n",
       " 'mountain',\n",
       " 'mountain',\n",
       " 'mountain',\n",
       " 'beach',\n",
       " 'mountain',\n",
       " 'mountain']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model_1.predict(test_generator)\n",
    "predicted_class_indices= (pred>0.5).astype(\"int32\")\n",
    "predictions = [labels[k[0]] for k in predicted_class_indices]\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.predict:  [[0.]]\n",
      "0\n",
      "mountain_2.png is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "mountain.jpg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "sea.jpeg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "00000003.jpg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "beach mountain.jpg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "mountain_3.jpeg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "00000002.jpg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "beach.jpeg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "sea.jpg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "beach2.jpeg is a beach\n"
     ]
    }
   ],
   "source": [
    "# from the internet\n",
    "file_path = '../dataset/beach_mountain/internet/' # current dir\n",
    "# file_path = '../dataset/beach_mountain/test/beach/' # current dir\n",
    "# file_path = '../dataset/beach_mountain/test/mountain/' # current dir\n",
    "test_files = os.listdir(file_path)\n",
    "\n",
    "for file in test_files:\n",
    "    # predicting images\n",
    "    path=file_path + file\n",
    "    img=image.load_img(path, target_size=img_dim)\n",
    "\n",
    "    x=image.img_to_array(img)\n",
    "    x=np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "    \n",
    "    print(\"model.predict: \", model_1.predict(images))\n",
    "\n",
    "    classes = (model_1.predict(images) > 0.5).astype(\"int32\")[0][0]\n",
    "    print(classes)\n",
    "\n",
    "    if classes>0:\n",
    "        print(file + \" is a mountain\")\n",
    "\n",
    "    else:\n",
    "        print(file + \" is a beach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.]]\n",
      "mountain.jpg is a beach\n"
     ]
    }
   ],
   "source": [
    "# from an image\n",
    "test_file = \"../dataset/beach_mountain/internet/mountain.jpg\"\n",
    "img = image.load_img(test_file, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "# classes = model.predict(images)\n",
    "# classes = np.argmax(model.predict(images), axis=-1)\n",
    "\n",
    "print(model_1.predict(images, verbose=1))\n",
    "\n",
    "classes = (model_1.predict(images) > 0.5).astype(\"int32\")[0][0]\n",
    "\n",
    "if classes>0:\n",
    "    print(test_file.split(\"/\")[-1] + \" is a mountain\")\n",
    "else:\n",
    "    print(test_file.split(\"/\")[-1] + \" is a beach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model mountain beach: using pretrained places365 + vgg16\n",
    "\n",
    "From notebook `./mountain_beach_tf_course_catdog_vgg16_places.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_pre_inceptionv3_100e_94\n",
    "path_model = path_saved + \"model_pre_vgg16_100e.h5\"\n",
    "model_4 = tf.keras.models.load_model(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "base_dir = \"../dataset/beach_mountain\"\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "train_beach_dir = os.path.join(train_dir, 'beach')\n",
    "train_moutain_dir = os.path.join(train_dir, 'mountain')\n",
    "\n",
    "validation_beach_dir = os.path.join(validation_dir, 'beach')\n",
    "validation_mountain_dir = os.path.join(validation_dir, 'mountain')\n",
    "\n",
    "test_beach_dir = os.path.join(test_dir, 'beach')\n",
    "test_moutain_dir = os.path.join(test_dir, 'mountain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 30\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "test_generator =  test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    batch_size  = batch_size,\n",
    "    class_mode  = 'binary', \n",
    "    target_size = img_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 8s 657ms/step - loss: 0.3494 - accuracy: 0.8550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34936755895614624, 0.8550000190734863]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "steps = test_generator.n // test_generator.batch_size\n",
    "model_4.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'beach', 1: 'mountain'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the labels\n",
    "labels = (test_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beach',\n",
       " 'mountain',\n",
       " 'beach',\n",
       " 'beach',\n",
       " 'mountain',\n",
       " 'beach',\n",
       " 'mountain',\n",
       " 'beach',\n",
       " 'mountain',\n",
       " 'mountain']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model_4.predict(test_generator)\n",
    "predicted_class_indices= (pred>0.5).astype(\"int32\")\n",
    "predictions = [labels[k[0]] for k in predicted_class_indices]\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.predict:  [[0.]]\n",
      "0\n",
      "mountain_2.png is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "mountain.jpg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "sea.jpeg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "00000003.jpg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "beach mountain.jpg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "mountain_3.jpeg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "00000002.jpg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "beach.jpeg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "sea.jpg is a beach\n",
      "model.predict:  [[0.]]\n",
      "0\n",
      "beach2.jpeg is a beach\n"
     ]
    }
   ],
   "source": [
    "# from the internet\n",
    "file_path = '../dataset/beach_mountain/internet/' # current dir\n",
    "# file_path = '../dataset/beach_mountain/test/beach/' # current dir\n",
    "# file_path = '../dataset/beach_mountain/test/mountain/' # current dir\n",
    "test_files = os.listdir(file_path)\n",
    "\n",
    "for file in test_files:\n",
    "    # predicting images\n",
    "    path=file_path + file\n",
    "    img=image.load_img(path, target_size=img_dim)\n",
    "\n",
    "    x=image.img_to_array(img)\n",
    "    x=np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "    \n",
    "    classes = model_1.predict(images)\n",
    "    print(\"model.predict: \", classes)\n",
    "\n",
    "    classes = (classes > 0.5).astype(\"int32\")[0][0]\n",
    "    print(classes)\n",
    "\n",
    "    if classes>0:\n",
    "        print(file + \" is a mountain\")\n",
    "\n",
    "    else:\n",
    "        print(file + \" is a beach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[0.]]\n",
      "mountain.jpg is a beach\n"
     ]
    }
   ],
   "source": [
    "# from an image\n",
    "test_file = \"../dataset/beach_mountain/internet/mountain.jpg\"\n",
    "img = image.load_img(test_file, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "# classes = model.predict(images)\n",
    "# classes = np.argmax(model.predict(images), axis=-1)\n",
    "\n",
    "print(model_1.predict(images, verbose=1))\n",
    "\n",
    "classes = (model_1.predict(images) > 0.5).astype(\"int32\")[0][0]\n",
    "\n",
    "if classes>0:\n",
    "    print(test_file.split(\"/\")[-1] + \" is a mountain\")\n",
    "else:\n",
    "    print(test_file.split(\"/\")[-1] + \" is a beach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with cat/dog model\n",
    "\n",
    "From notebook: `./cat_dog_vn_like.jpynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_model_2 = path_saved + \"cat_dog\"\n",
    "# model_2 = tf.keras.models.load_model(path_model_2)\n",
    "\n",
    "path_model = path_saved + \"cat_dog/model_cat_dog_vn_like.h5\"\n",
    "model_2 = tf.keras.models.load_model(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (192, 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_192 (Functi (None, 6, 6, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                81984     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 2,340,098\n",
      "Trainable params: 82,114\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../dataset/cats_and_dogs_filtered'\n",
    "\n",
    "train_dir = os.path.join( base_dir, 'train')\n",
    "validation_dir = os.path.join( base_dir, 'validation')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = img_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'cats', 1: 'dogs'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = (validation_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = validation_generator.n // validation_generator.batch_size\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00603913 0.99396086]]\n",
      "[1]\n",
      "it's a dog\n"
     ]
    }
   ],
   "source": [
    "path = base_dir + \"/test/dog4.jpeg\"\n",
    "img = image.load_img(path, target_size=img_dim)\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "print(model_2.predict(images))\n",
    "model_2.predict(images)\n",
    "\n",
    "# classes = (model_2.predict(images) > 0.5).astype(\"int32\")[0][0]\n",
    "classes = np.argmax(model_2.predict(images), axis=1)\n",
    "\n",
    "print(classes)\n",
    "if classes[0]>0:\n",
    "    print(\"it's a dog\")\n",
    "else:\n",
    "    print(\"it's a cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "dog3.jpg is a cat\n",
      "1\n",
      "dog1.jpg is a dog\n",
      "0\n",
      "cat.jpeg is a cat\n",
      "1\n",
      "cat_2.jpeg is a dog\n",
      "1\n",
      "dog4.jpeg is a dog\n",
      "1\n",
      "dog2.jpg is a dog\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# file_path = './test_files/' # current dir\n",
    "file_path = '../dataset/cats_and_dogs_filtered/test/' # current dir\n",
    "test_files = os.listdir(file_path)\n",
    "\n",
    "for file in test_files:\n",
    "    # predicting images\n",
    "    path=file_path + file\n",
    "    img=image.load_img(path, target_size=(150, 150))\n",
    "\n",
    "    x=image.img_to_array(img)\n",
    "    x=np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "\n",
    "#     classes = (model_1.predict(images) > 0.5).astype(\"int32\")[0][0]\n",
    "    classes = np.argmax(model_2.predict(images), axis=1)[0]\n",
    "    print(classes)\n",
    "\n",
    "    if classes>0:\n",
    "        print(file + \" is a dog\")\n",
    "\n",
    "    else:\n",
    "        print(file + \" is a cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with cat/dog -> model md_cp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = path_saved + \"cat_dog/model_cat_dog_md_cp1.h5\"\n",
    "model_3 = tf.keras.models.load_model(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../dataset/cats_and_dogs_filtered'\n",
    "\n",
    "train_dir = os.path.join( base_dir, 'train')\n",
    "validation_dir = os.path.join( base_dir, 'validation')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = img_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'cats', 1: 'dogs'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = (validation_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = validation_generator.n // validation_generator.batch_size\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model_3.predict(validation_generator)\n",
    "# predicted_class_indices= (pred>0.5).astype(\"int32\")\n",
    "# predictions = [labels[k[0]] for k in predicted_class_indices]\n",
    "# predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.03812e-29]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = base_dir + \"/test/dog4.jpeg\"\n",
    "path = base_dir + \"/test/cat.jpeg\"\n",
    "img = image.load_img(path, target_size=img_dim)\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "print(model_3.predict(images))\n",
    "\n",
    "classes = (model_3.predict(images) > 0.5).astype(\"int32\")[0][0]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "dog3.jpg is a dog\n",
      "1\n",
      "dog1.jpg is a dog\n",
      "0\n",
      "cat.jpeg is a cat\n",
      "0\n",
      "cat_2.jpeg is a cat\n",
      "1\n",
      "dog4.jpeg is a dog\n",
      "1\n",
      "dog2.jpg is a dog\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# file_path = './test_files/' # current dir\n",
    "file_path = '../dataset/cats_and_dogs_filtered/test/' # current dir\n",
    "test_files = os.listdir(file_path)\n",
    "\n",
    "for file in test_files:\n",
    "    # predicting images\n",
    "    path=file_path + file\n",
    "    img=image.load_img(path, target_size=img_dim)\n",
    "\n",
    "    x=image.img_to_array(img)\n",
    "    x=np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "\n",
    "    classes = (model_3.predict(images) > 0.5).astype(\"int32\")[0][0]\n",
    "    print(classes)\n",
    "\n",
    "    if classes>0:\n",
    "        print(file + \" is a dog\")\n",
    "\n",
    "    else:\n",
    "        print(file + \" is a cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
